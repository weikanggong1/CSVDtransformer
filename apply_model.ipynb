{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c97d04f8-ca1a-44f2-ba89-c704a63ff042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CSVDtransformer\n",
    "from dataloader import load_Nifti_data_multimodal\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "device = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18be6b99-ea92-47ed-aa5b-214e066a87ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CSVDtransformer(\n",
       "  (patch_embed): ParameterList(\n",
       "      (0): Object of type: PatchEmbed\n",
       "    (0): PatchEmbed(\n",
       "      (proj): Conv1d(1, 256, kernel_size=(2048,), stride=(2048,))\n",
       "    )\n",
       "  )\n",
       "  (in_blocks): ModuleList(\n",
       "    (0-5): 6 x Block(\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (attn_drop): Dropout(p=0, inplace=False)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj_drop): Dropout(p=0, inplace=False)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): Block(\n",
       "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "      (attn_drop): Dropout(p=0, inplace=False)\n",
       "      (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (proj_drop): Dropout(p=0, inplace=False)\n",
       "      (rotary_emb): RotaryEmbedding()\n",
       "    )\n",
       "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (out_blocks): ModuleList(\n",
       "    (0-5): 6 x Block(\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=256, out_features=768, bias=False)\n",
       "        (attn_drop): Dropout(p=0, inplace=False)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj_drop): Dropout(p=0, inplace=False)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (drop_layer): Dropout(p=0, inplace=False)\n",
       "  (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (latent_pred): ParameterList(\n",
       "      (0): Object of type: Linear\n",
       "      (1): Object of type: Linear\n",
       "    (0): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####load csvd models\n",
    "patch_size = 1024\n",
    "embed_dim = 512\n",
    "depth = 6\n",
    "num_heads = 8\n",
    "nclass_pred1 = [4, 4, 7, 4, 2, 3]\n",
    "shift_index = np.load('./model_ckpt/csvd_shift_index_t2.npy')\n",
    "shift_index1 = np.load('./model_ckpt/csvd_shift_index_t1.npy')\n",
    "\n",
    "model = CSVDtransformer(input_size=[len(shift_index), len(shift_index)], patch_size=[patch_size, patch_size], in_chans = 1, out_chans=1, embed_dim=embed_dim, \n",
    "                                depth=depth, num_heads=num_heads, mlp_ratio=4.,qkv_bias=False, qk_scale=None, \n",
    "                                norm_layer=torch.nn.LayerNorm, mlp_time_embed=False,\n",
    "                                use_checkpoint=False, conv=True, skip=False, \n",
    "                                attn_drop=0,\n",
    "                                proj_drop=0, \n",
    "                                pred_drop=0,\n",
    "                                out_class=nclass_pred1,\n",
    "                                cov_dim=0)\n",
    "model.eval()\n",
    "state_dic = torch.load('./model_ckpt/csvd_model.pth', 'cpu')\n",
    "xx, yy = model.load_state_dict(state_dic, strict=False)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "####load cmb models\n",
    "patch_size = 2048\n",
    "embed_dim = 256\n",
    "depth = 12\n",
    "num_heads = 8\n",
    "nclass_pred2 = [2, 3]\n",
    "shift_index2 = np.load('./model_ckpt/csvd_shift_index_swi.npy')\n",
    "\n",
    "model1 = CSVDtransformer(input_size=[len(shift_index2)], patch_size=[patch_size], in_chans = 1, out_chans=1, embed_dim=embed_dim, \n",
    "                                depth=depth, num_heads=num_heads, mlp_ratio=4.,qkv_bias=False, qk_scale=None, \n",
    "                                norm_layer=torch.nn.LayerNorm, mlp_time_embed=False,\n",
    "                                use_checkpoint=False, conv=True, skip=False, \n",
    "                                attn_drop=0,\n",
    "                                proj_drop=0, \n",
    "                                pred_drop=0,\n",
    "                                out_class=nclass_pred2,\n",
    "                                cov_dim=0)\n",
    "model1.eval()\n",
    "state_dic = torch.load('./model_ckpt/cmb_model.pth', 'cpu')\n",
    "xx, yy = model1.load_state_dict(state_dic, strict=False)\n",
    "print(xx)\n",
    "print(yy)\n",
    "model1.to(device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03bd339a-d7cc-4707-86c2-315a101c1c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for analysis...\n",
      "['/public/home/gongwk/Notebook_code/csvd_proj/code_release/example_data/sub-0001/T1_brain_1mm_stdspace.nii.gz', '/public/home/gongwk/Notebook_code/csvd_proj/code_release/example_data/sub-0002/T1_brain_1mm_stdspace.nii.gz', '/public/home/gongwk/Notebook_code/csvd_proj/code_release/example_data/sub-0003/T1_brain_1mm_stdspace.nii.gz']\n",
      "['/public/home/gongwk/Notebook_code/csvd_proj/code_release/example_data/sub-0001/T2_brain_1mm_stdspace.nii.gz', '/public/home/gongwk/Notebook_code/csvd_proj/code_release/example_data/sub-0002/T2_brain_1mm_stdspace.nii.gz', '/public/home/gongwk/Notebook_code/csvd_proj/code_release/example_data/sub-0003/T2_brain_1mm_stdspace.nii.gz']\n",
      "['/public/home/gongwk/Notebook_code/csvd_proj/code_release/example_data/sub-0001/SWI_brain_1mm_stdspace.nii.gz', '/public/home/gongwk/Notebook_code/csvd_proj/code_release/example_data/sub-0002/SWI_brain_1mm_stdspace.nii.gz', '/public/home/gongwk/Notebook_code/csvd_proj/code_release/example_data/sub-0003/SWI_brain_1mm_stdspace.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/public/home/gongwk/Notebook_code/csvd_proj/code_release/example_data/'\n",
    "data_list_t1 = sorted(glob.glob(f'{data_dir}/*/T1_brain_1mm_stdspace.nii.gz'))\n",
    "data_list_t2 = sorted(glob.glob(f'{data_dir}/*/T2_brain_1mm_stdspace.nii.gz'))\n",
    "data_list_swi = sorted(glob.glob(f'{data_dir}/*/SWI_brain_1mm_stdspace.nii.gz'))\n",
    "print('Data for analysis...')\n",
    "print(data_list_t1)\n",
    "print(data_list_t2)\n",
    "print(data_list_swi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2066c0d-4adb-4954-9ac0-5daf7094755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 218, 182)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "##process data\n",
    "import nibabel as nib\n",
    "##read in mask\n",
    "info = nib.load('./wm_mask_1mm.nii.gz')\n",
    "image_mask = info.get_fdata()\n",
    "image_mask = torch.FloatTensor(image_mask).unsqueeze(0).unsqueeze(0)        \n",
    "image_mask[torch.isnan(image_mask)] = 0.0\n",
    "image_mask[torch.isinf(image_mask)] = 0.0      \n",
    "image_mask = torch.nn.functional.interpolate(image_mask, (182, 218, 182), mode='nearest')[0,0,:,:,:].numpy()\n",
    "image_mask = image_mask>0.2\n",
    "print(image_mask.shape)\n",
    "\n",
    "\n",
    "##data loader\n",
    "dataset = load_Nifti_data_multimodal(data_list_t1, data_list_t2, data_list_swi, image_mask)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "print(len(loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69e05251-acca-4836-a238-740eb373cfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference begin...\n",
      "0\n",
      "Inference finished...\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print('Inference begin...')\n",
    "with torch.no_grad():\n",
    "    \n",
    "    risk_score = np.zeros((len(data_list_t1), 6))\n",
    "\n",
    "    for batch_idx, _batch in enumerate(loader):\n",
    "        print(batch_idx)\n",
    "        # print(_batch[0].shape)\n",
    "        data_in_t2 = _batch[0].to(device)[:,:,shift_index]       \n",
    "        data_in_t1 = _batch[1].to(device)[:,:,shift_index1]\n",
    "        data_in_swi = _batch[2].to(device)[:,:,shift_index2]\n",
    "        \n",
    "        pred = model([data_in_t2, data_in_t1])\n",
    "\n",
    "        pred1 = model1([data_in_swi])\n",
    "        \n",
    "        for ijk in range(0,5):\n",
    "            prob = torch.nn.functional.softmax(pred[ijk].detach(), dim=1).cpu().numpy()\n",
    "            risk_score[_batch[-1].cpu().numpy(),ijk] = np.sum(prob * np.expand_dims(np.arange(0, pred[ijk].shape[1]), 0), axis=1)\n",
    "\n",
    "        prob = torch.nn.functional.softmax(pred1[0].detach(), dim=1).cpu().numpy()\n",
    "        risk_score[_batch[-1].cpu().numpy(),-1] = np.sum(prob * np.expand_dims(np.arange(0, pred1[0].shape[1]), 0), axis=1)\n",
    "\n",
    "print('Inference finished...')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33f589c9-4e84-481d-8247-7b93910546a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.87969687, 2.65044594, 5.10771264, 1.46663133, 0.92889506,\n",
       "        0.99564123],\n",
       "       [2.97869665, 2.98211055, 5.90563574, 1.80747577, 0.90989554,\n",
       "        0.99597627],\n",
       "       [2.97451527, 2.42044102, 5.69024676, 1.67382421, 0.95752406,\n",
       "        0.06210529]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30189706-bfa7-4c16-8d00-2bc86db166ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results1 = pd.DataFrame({'t1': data_list_t1, 't2': data_list_t2, 'swi': data_list_swi})\n",
    "all_results2 = pd.DataFrame(risk_score, columns = ['PWMH','DWMH','Fezakasscore','EPVS','LI', 'CMB'])\n",
    "all_results = pd.concat((all_results1, all_results2), axis=1)\n",
    "all_results.to_csv('./Inference_results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "258863c9-d45b-4264-88e0-1c021b220409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>swi</th>\n",
       "      <th>PWMH</th>\n",
       "      <th>DWMH</th>\n",
       "      <th>Fezakasscore</th>\n",
       "      <th>EPVS</th>\n",
       "      <th>LI</th>\n",
       "      <th>CMB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/public/home/gongwk/Notebook_code/csvd_proj/co...</td>\n",
       "      <td>/public/home/gongwk/Notebook_code/csvd_proj/co...</td>\n",
       "      <td>/public/home/gongwk/Notebook_code/csvd_proj/co...</td>\n",
       "      <td>2.879697</td>\n",
       "      <td>2.650446</td>\n",
       "      <td>5.107713</td>\n",
       "      <td>1.466631</td>\n",
       "      <td>0.928895</td>\n",
       "      <td>0.995641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/public/home/gongwk/Notebook_code/csvd_proj/co...</td>\n",
       "      <td>/public/home/gongwk/Notebook_code/csvd_proj/co...</td>\n",
       "      <td>/public/home/gongwk/Notebook_code/csvd_proj/co...</td>\n",
       "      <td>2.978697</td>\n",
       "      <td>2.982111</td>\n",
       "      <td>5.905636</td>\n",
       "      <td>1.807476</td>\n",
       "      <td>0.909896</td>\n",
       "      <td>0.995976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/public/home/gongwk/Notebook_code/csvd_proj/co...</td>\n",
       "      <td>/public/home/gongwk/Notebook_code/csvd_proj/co...</td>\n",
       "      <td>/public/home/gongwk/Notebook_code/csvd_proj/co...</td>\n",
       "      <td>2.974515</td>\n",
       "      <td>2.420441</td>\n",
       "      <td>5.690247</td>\n",
       "      <td>1.673824</td>\n",
       "      <td>0.957524</td>\n",
       "      <td>0.062105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  t1  \\\n",
       "0  /public/home/gongwk/Notebook_code/csvd_proj/co...   \n",
       "1  /public/home/gongwk/Notebook_code/csvd_proj/co...   \n",
       "2  /public/home/gongwk/Notebook_code/csvd_proj/co...   \n",
       "\n",
       "                                                  t2  \\\n",
       "0  /public/home/gongwk/Notebook_code/csvd_proj/co...   \n",
       "1  /public/home/gongwk/Notebook_code/csvd_proj/co...   \n",
       "2  /public/home/gongwk/Notebook_code/csvd_proj/co...   \n",
       "\n",
       "                                                 swi      PWMH      DWMH  \\\n",
       "0  /public/home/gongwk/Notebook_code/csvd_proj/co...  2.879697  2.650446   \n",
       "1  /public/home/gongwk/Notebook_code/csvd_proj/co...  2.978697  2.982111   \n",
       "2  /public/home/gongwk/Notebook_code/csvd_proj/co...  2.974515  2.420441   \n",
       "\n",
       "   Fezakasscore      EPVS        LI       CMB  \n",
       "0      5.107713  1.466631  0.928895  0.995641  \n",
       "1      5.905636  1.807476  0.909896  0.995976  \n",
       "2      5.690247  1.673824  0.957524  0.062105  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a41e44-3f0b-4e03-86c1-b24d95a4f8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ba9a2-2d41-4076-8b47-b0206dceac7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
